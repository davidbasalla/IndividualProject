\documentclass[a4paper,11pt,titlepage]{article}
\usepackage[margin=2cm]{geometry}

\usepackage[nodayofweek]{datetime}
\longdate

\usepackage{fancyhdr}
\pagestyle{fancyplain}
\fancyhf{}
\lhead{\fancyplain{}{M.Sc.\ Individual Project Literature Survey}}
\rhead{\fancyplain{}{\today}}
\cfoot{\fancyplain{}{\thepage}}
\usepackage{adjustbox}

\usepackage[english]{babel}
\usepackage[utf8x]{inputenc}
\usepackage{float}

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{cite}



\title{Browser-based Medical Image Viewer using WebGL \\\Large{--- Literature Review ---}}
\author{David Basalla\\
       \{db913\}@ic.ac.uk\\ \\
       \small{Supervisor: Dr.\ Ben Glocker}\\
       \small{Course: CO541, Imperial College London}
}

\begin{document}
\maketitle

\section{Introduction}
When creating MRI scans, the resulting image files contain a wealth of data and require specific software packages to view them comprehensively. Among others, the files include high-range images across several dimensions (usually at least X, Y and Z) through a volume. This creates the issue for the users to have the appropriate software installed on their local desktop computer. Additionally software developers have to cater for different operating systems. The goal of this project is to simplify the process of viewing and manipulating these images (specifically the NifTi format) by creating a web-browser-based medical image viewer with an intuitive interface for viewing multiple files and allowing for creation, viewing and manipulation of label maps and other methods of annotating these images. The rationale behind this is to facilitate users to conveniently share and annotate medical image files independently of location or type of computer, following the "Software as a Service" paradigm.

\section{Literature Review}

\subsection{Medical Imaging}

- general uses
	- what do doctors use it for
	- 3d data

- 2D Views/Slices
	talk about details, pixel length etc
	easier to measure, be exact
	people still go through slice by slice
	imagining what the 3D structure is

- 3D View
	easier to get an overview
	
- Comparing images is useful	
	
- label maps
	
	
\subsection{File Formats}
- Talk about DICOM/ PACS ?? \\
- NIFTI\\
- NRRD\\
- mention slices\\
- arbitrary number of dimensions, but for scope of the project, only the first 3, X, Y, Z will be looked at.


	


\subsection{Desktop Applications}

There exists a variety of desktop software to date allows viewing of medical image data. For this project, a selection of programs have been tested and analysed for functionality.

\subsubsection{MITK 3M3}
     Firstly, MITK 3M3 by Mint Medical and German Cancer Research Center allows for easy viewing of a variety of medical image file formats. The layout of the views is customisable and by default shows the X, Y, Z dimension and a 3D view of all 3 dimensions together. (picture) There is a universal range slider that affects all images at once. Labelmaps (called Segmentations) can be added to a scan file, as sub layers and a range of paint tools are provided to colour in regions of the scan. An arbitrary number of layers can be created and saved out as separate files. 
     Furthermore it can create a 3D volume renderings, applying image filters and supplies measuring tools. In general it is a well rounded product with intuitive controls so will serve as a good benchmark test for the final product.

\subsubsection{Imview}
Imview is a medical image viewer created by Ben Glocker, which again allows the user to load scan files and inspect the individual slices of each axis. The user can perform flip transformations and apply different colour look-ups to the image, such as Colormap Jet which looks like a heat map. It also provides the option of displaying an information overlay with stats about the image.

\begin{figure}[ht!]
\centering
\includegraphics[width=80mm]{graphics/imview_01.png}
\caption{Screenshot of Imview}
\label{fig:UIdesign1}
\end{figure}

\subsubsection{3DSlicer}
3D Slicer is a free open source software that provides a modular platform for image analysis and visualization. Of all the packages, this tool seems to be the most feature rich, which is not surprising as it is funded by a number of American organisations such as  the National Alliance for Medical Image Computing, Neuroimage Analysis Center and others. Although it features a wide variety of tools, the focus will be on the ones relevant to this project. 3D Slicer allows for loading of different files of different formats. It provides options to composite different slices on top of each other for comparison. It supports hardware accelerated volumetric rendering of medical image data. It is widely customisable with global settings. Layouts are also customisable. It has an extensive set of tools for manual and automatic image segmentation. It has an in-built feature to download sample data, which would be a useful inclusion for the web app project. Another powerful feature is that 3D Slicer allows the addition of new functionality and provides a number of generic features not available in competing tools. All in all, 3DSlicer appears like a well designed, user-friendly program that has an overwhelming amount of functionality. It will be another good benchmark and inspiration for this project.

\subsubsection{MIview}
MIview was programmed by Greg Book, is open source and provides much the same functionality as MITK. MIView is an OpenGL based medical image viewer which aims to support a wide range of medical imaging files such DICOM, Nifti, and raster images. It can also read and convert DICOM mosaic images. The main goal of MIView is to provide a platform to load any type of medical image and be able to view and manipulate the image. Volume rendering is also supported. Control-wise, support for mouse-wheel scrolling seems erratic, which makes navigation through the slices more cumbersome. Also the buttons tend to be quite small which also does not improve the user experience. It does not appear to support the loading of multiple files together. A number of predefined color look-up tables are provided.

\subsubsection{Photoshop}
Looking further afield to some graphical editing software programs, some interesting functionality can be discovered. Adobe's Photoshop is well known software for creating and manipulating 2D imagery. When editing an image, the user works with a document. The user can add as many layers as required and edit each layer individually. The layers are composited to form the whole picture. Each layer's opacity and compositing/blending mode can be specified. This could be a worth while to emulate for comparing different medical image files in the web app.

\begin{figure}[ht!]
\centering
\includegraphics[width=80mm]{graphics/photoshop_01.png}
\caption{Layer compositing in Photoshop}
\label{fig:UIdesign1}
\end{figure}

\subsubsection{Nuke}
The Foundry's Nuke is a compositing package which is used in the Visual Effects Industry to edit and composite 2D images with each other. It is used among others at high profile VFX companies such as Industrial Light and Magic and Weta Digital). The interface differs from Photoshop in that it provides the user with a workplace where any number of nodes can be created. When selecting any node, a graphical display will appear. These nodes can be linked together and do anything from loading a specific image file, transforming the whole node tree or applying an image filter such a film grain. The power of this approach is the modular nature of a tree. Any node can be taken out and reinserted at another place into the tree, thereby changing the final image. Additionally, for comparing different images, by default the software supplies two image buffers which the user can fill with any image of his choice (including of course the result from any node tree in his workspace). Once both buffers are filled, the user can easily toggle between the two images, blend between them by setting the opacity and even use a slider to reveal just a portion of either image. So while Nuke's node-based approach may be overkill for this project, Nuke's image blending seems quite desirable for this project as it would give the user a variety of ways in which he can compare multiple images. 

\begin{figure}[ht!]
\centering
\includegraphics[width=170mm]{graphics/nuke_02.png}
\caption{Nuke's node-based workspace}
\label{fig:UIdesign1}
\end{figure}


\subsection{Interactive Web Graphics}

In order to create an interactive web browser application that provides graphical feedback, the available tools for creating 2D and 3D graphics in a web browser have to be considered. Generally, in the past web browsers have provided several different methods to display 2D and 3D graphics on screen, and only recently with the introduction of HTML5 and WebGL has a widely-conformed standard emerged.

\subsubsection{2D Graphics}

Displaying 2D graphics has long been an integral part of web browsers. Aside from simply displaying an image file, there used to be different web browser plug-ins which would display more interactive graphics and videos. Adobe's FlashPlayer and JavaApplets were very common for this purpose.


Talk about canvas, other alternatives
Flash

CSS is used to alter an element's style property, but this is not really suitable for creating intricate 2D graphics, as it is typically used to style the look of HTML elements. There are no custom draw commands.

Scalable Vector Graphics (SVG) is like HTML for graphics. It is a markup language for describing all aspects of an image or Web application, from the geometry of shapes, to the styling of text and shapes, to animation, to multimedia presentations including video and audio. It is fully interactive, and includes a scriptable DOM as well as declarative animation (via the SMIL specification). It supports a wide range of visual features such as gradients, opacity, filters, clipping, and masking.
The use of SVG allows fully scalable, smooth, reusable graphics, from simple graphics to enhance HTML pages, to fully interactive chart and data visualization, to games, to standalone high-quality static images. SVG is natively supported by most modern browsers (with plugins to allow its use on all browsers), and is widely available on mobile devices and set-top boxes. All major vector graphics drawing tools import and export SVG, and they can also be generated through client-side or server-side scripting languages.

The Canvas API is a client-side scripting technology to allow for the rich creation or alteration of raster images (bitmaps) . It uses vector-based programmatic methods to create shapes, gradients, and other graphical effects, and because it has no DOM, it can perform very quickly. Dedicated scripters can develop games or even full-featured applications using the Canvas API, alone or integrated into HTML or SVG. It is supported natively in most modern browsers (with script libraries extending support to all major browsers), and even on some mobile devices.

\subsubsection{3D Graphics}

Broadly speaking, the history of 3D Graphics can be divided into the time before and after the standardisation of WebGL. Before WebGL the standard way to display 3D graphics in a web browser were tied to a browser plug-in that the user would have to download locally to their computer.

Examples JavaApplets, Flash, O3D

WebGL is a JavaScript API that exposes a computers GPU to the web browser and allows for displaying of complex three dimensional graphics as seen in comparable desktop applications. Although only initially relased in 2011, WebGL is widely supported by most modern browsers (reference), so it's a good time to make use of this for medical visualisation. WebGL is based on OpenGL ES 2.0 and uses the HTML5 canvas element and is accessed using Document Object Model interfaces.

History of WebGL. 

Nowadays, most libraries make use of WebGL and even libraries that used to require a plug-in (example) have now been ported to use WebGL. 
Games in WebGL


\subsection{Web Framework XTK}

As suggested in the project specification, the goal of this project is to use the \textit{X Toolkit}(\textit{XTK}), a JavaScript-based framework for visualizing and interacting with medical imaging data using \textit{WebGL}. It was developed and maintained by Haehn et al the of the Fetal-Neonatal Neuroimaging and Developmental Science Center at Childrens Hospital Boston, Harvard Medical School, US (reference). \textit{XTK} provides an API to load medical images, based on \textit{WebGL} technology for displaying 3D graphics and the \textit{HTML5} canvas elements to display 2D components. It hides a lot of the low-level elements of \textit{WebGL} and is designed to quickly load and configure \textit{DICOM} files of various types. The library is well documented and comes with several tutorials as well as a number of example applications, which will be discussed in the next section.
The XTK library also provides a module for creating User Interface (UI), that can be overlaid on top of the image viewers, with easy controls to connect the image content with the UI controls.


\subsection{Web Applications}
The \textit{XTK} library also provides links to example applications. One of these is \textit{SliceDrop} which has written by the \textit{XTK} developers. It provides part of the desired functionality and shows off the possibilities provided by \textit{XTK}, but also outlines some of its short comings. Like the desktop software \textit{MITK}, the user can load a file and view it in the standard 4 views, split into 3D and 2D windows. The layout of these views is somewhat customisable, although not to the extent of the \textit{MITK}. The user can interact with the images by scrolling the mouse wheel, which changes the index of the current slice. An interesting feature which has been added lately is the incorporation of popular file sharing site \textit{DropBox} to allow users to share files more easily across the internet.

There appear to be some bugs in \textit{SliceDrop}. When loading \textit{NRRD} files, as the image is offset and not centered. The image brightness controls seem not calibrated correctly, as with little mouse interaction, the brightness will clamp to white or black and can not be reset other than restarting the program (refreshing the page for web-apps). Furthermore the app does not allow to load custom labelmaps. Also the viewers provide some functionality which is not clearly communicated to the user, such as holding the 'shift' button and move the mouse will adjust the slice index of the other viewers. In general \textit{SliceDrop} has less than the minimum functionality required for this project, but shows the potential of the \textit{XTK} library. 

\textit{Brainbook} (reference) is a web-app which builds on and extends the features of \textit{SliceDrop} by adding painting tools. It allows the user to paint onto a given file with a standard brush a number of auto selection tools which will fill out a region in 2D or 3D space. The web app offers to save the file, but at time of writing this feature was not working correctly. Since heavily based on \textit{SliceDrop}, it features similar advantages and disadvantages, but provides the painting functionality that is desirable for this project.

- Other Examples (functionality, issues)\\
- Various DICOM viewers, not compatible with NII/NRRD files tho...
- Oviyam, requires server installation, not tried as too cumbersome

\subsection{Web Frameworks for Single Page Apps}

Modern Webpages which require more complex behaviour than just displaying information can get quite involved. Generally it takes at least HTML, CSS and JavaScrip to create a useful website. It is possible to include the code from each language in the main index.html file, but this is undesirable as it lacks modularity and will be hard to test and debug.

At the time of writing, Backbone seems to be a good choice to manage the complexity and structure of the project. Backbone is used to structure client-side applications (those that run in a web browser). It was written by Jeremy Ashkenas and is designed for developing single-page web applications, and for keeping various parts of web applications synchronized. It is based on the model–view–presenter (MVP) application design paradigm, providing Events, Models, Collections and Views. Models represent the information in class like structures, Collections are lists of Models and Views handle the visual representation on the actual HTML site. Finally Events are used to keep track of state changes across the website elements, models and views. It builds on JQuery.js and Underscore.js, both libraries which simplify dealing with HTML elements.

Regarding the design aspect, it looks like twitter-bootstrap.js supplies a convenient library for creating visually pleasing user interface elements. This will cut down on having to spend time to design custom elements with CSS and JavaScript. Bootstrap.js supplies buttons, drop-down menus and commonly-used icons.

As this project will make of several modules, it will be important to manage the dependencies of the modules. For example Underscore.js and JQuery.js will need to load before Backbone.js is used. XTK and twitter-boostrap are additional modules that will have to be loaded. Require.js is a javascript library that provide the ability to asynchronously load nested dependencies. Traditionally javascript files or modules are loaded sequentially, where the order matters in case a module depends on another module. Require.js will make it possible to split up everything into neat modules and facilitate testing of all the components.




\section{Requirements}

The goal of this project is to build a web browser based Medical Image Viewer. This will be achieved by making use of WebGL to display 2D and 3D graphics. In general the project aims to provide similar functionality and user experience as the desktop application MITK (discussed earlier). The essential requirements are as follows:

\begin{itemize}
\item The user can load and view a scan file (of type NIfTI)
\item The user can view a file in 2D and 3D
\item The user can easily navigate through the 2D and 3D viewers, with emphasis on intuitive user experience
\item The web-app provides controls for viewing the scan files at different brightness and contrast levels
\item The user can load and view a labelmap for a given scan file
\item The user can load additional scan or label maps into the viewer and compare them to previously loaded files with a set of intuitive controls
\item Provide different color-lookups (for label-maps, heat maps)
\item Provide sample data to use if user has no files of his own
\end{itemize}

Given enough time, secondary requirements can be implemented, which are considered to be more complicated:

\begin{itemize}
\item The user can paint a custom labelmap for a given scan file with a set of intuitive tools. The primary goal will be that the user can paint areas manually on individual slices. Provided there is enough time, some semi-automatic painting tools will also be implemented that will allow the user to specify regions in the 3D space with automatic selection tools. 
\item The user can save a labelmap to his computer
\item The user can create and save custom annotation maps to label given scans
\item The web app provides a method for sharing  means of sharing data across the internet (similar to the DropBox implementation in SliceDrop)
\item The web app provides image filters that can be applied to a scan or label map
\item The web app provides measuring tools that can be applied to a scan or label map
\item A three dimensional, parameterised model of the scan be viewed in the 3D view
\end{itemize}

\section{Use Cases}

A small selection of use cases have been discussed with the project supervisor. The following were suggested:

\begin{itemize}

\item A user loads two medical images files from a patient that has undergone brain surgery. The user wants to compare the scans from before the operation to afterwards. The user needs to be able to compare the two files in meaningful ways, with tools for image comparison and compositing.

\item A user wants to create a custom label map by highlighting a certain section of a loaded scan. The user can use provided paint tools to paint individually on each slice, or alternatively use semi-automatic tools like filling in regions within a given color range to speed up this process. The user can save out this custom label map in NIfTi format.

\item The user wants to create annotations for a file. He can use the software to create annotated planar or cuboid regions to for example specify where a given organ is in the scan. The software provides intuitive controls and helpful visual feedback to facilitate this process. The user can save out this files as a custom data file.

\item A user wants to communicate with another user who is not present in the same location. The first user can use the software to provide links to specified medical image files to the second user. The second user can load these files with the software for analysis.

\end{itemize}

\section{Progress}

Some effort has already gone into planning and implementing the project. The initial plan was to create a working prototype in a relatively short time. This was however foiled by the complexity of the task of creating a functioning web-app. At first, tests were done building on tutorials that are provided by the XTK toolkit site. This included a simple HTML front end as well as some javascript files to handle the XTK objects.

Loading local files in a web browser proved to be one of the early issues. Due to security issues, Chrome and other browsers do not allow local files to be loaded onto the HTML canvas element, tying into the same origin policy that browsers try to uphold. A way around this was found by analysing the SliceDrop code and noticing that it uses the HTML FileReader to convert the local file into a byteArray which can then be loaded into the XTK viewers.

Having some concerns that modifications will have to be made to the XTK toolkit, the author managed to successfully clone and fork the project from github. Since things are never as easy as hoped for, editing and rebuilding the toolkit proved tricky, since it employs yet another unknown JavaScript library, called GoogleClosure.js. After learning how to use this module and other little issues mainly due XTK being developed on Linux and not Windows, the OS the project is currently being developed on, the toolkit managed to recompile successfully.

Once some basic tests with the XTK toolkit proved that it could be used to display local scan files, it was time to start adding some functionality to the website. This quickly showed that the previous implementation of the HTML website was highly naive, and that it would require a restructuring from the ground up. Almost as an example of why web programming can be tricky, the HTML site was mixing elements from HTML, CSS and JavaScript without much structure. When separating out the JavaScript parts into separate files, the issue of module loading and dependency became apparent.

From the group project earlier in the term, the author was aware of JavaScript libraries that aid in structuring a web-app such as Backbone.js, Require.js and JQuery.js. So the next few days were spent trying to get to grips with these and understanding generally how web apps are built. This seems to be a rich topic in its own right, and will undoubtedly take more time still to become comfortable with. However it helps that Backbone tends to enforce a somewhat object-oriented structure, which ties development back to principles learned in the Masters course over the year. Even when starting to implement the Backbone it becomes apparent how easy it is to fall back into mixing different language in the files and to enforce that every component just does the one task it is supposed to do. Talk about templates...

When realising that an object-orientated structure can and should be applied to the project, it prompted the author to create a UML diagram with possible class design (see Appendix). This will prove useful when implementing the Backbone components and helps to visualise the flow of control of the web-app. Additionally, visual UI design have been made to show how the front-end would look like to the user and what controls would available to him or her (see Appendix). After it some research it also became apparent that yet another JavaScript library called twitter-bootstrap is very popular among the web community to create UI designs for buttons and menus, so time was spent learning how to tie this into the project.
Currently, the plan is still to create a working prototype that has all the essential requirements fulfilled.


\subsection{Concerns}

\subsubsection{XTK}

So far, testing the XTK toolkit has revealed some concerns. In general the library is not as modularised as hoped for, as it does not seem possible to add a custom number of label maps. There is at present also no way to paint a custom label map. However, as already discussed, it is possible to fork the project from github and introduce changes, so this will have to be explored when adding additional features.

Other useful functionality is hard-coded into the library, which may need suppressing or changing of the input triggers. For example currently, the are no display lines for all viewers when one clicks or moves the mouse over one view. Furthermore the user has to hold down the shift key and move the mouse over a view, to affect the slice indices of the other views. This can hopefully be tweaked in the module.

Some design decisions in the XTK library are so far not ideal. For example when loading a file into a XTK volume, (which is then attached to a XTK renderer), the actual loading of the file happens only once the first XTK renderer has its render() function called. In the case of having multiple XTK renderers initiated(as the standard 3D/X/Y/Z format), the other renderers have to wait until the loading is complete and can only afterwards call their render() function. If calling render before the loading is complete, according to the XTK developers, the internal object data can get corrupted. For the scope of this project, this is not ideal as it implies that further management is required.

There also appears to be a bug with loading NRRD files, as they as displayed with an offset in the 2D and 3D viewers. This behaviour is visible in SliceDrop as well as in the XTK tutorials. The XTK developers have been made aware of the problem.

It appears that there is only a very small and inactive community for the XTK library. There is a group on the popular tech forum StackOverflow but questions are being asked infrequently and get answered even more rarely.

One strategy to follow will be to use the XTK renderers solely for their image generation and override all the UI functionality. This could be achieved by creating a custom renderer class that simply copies the imageData from the XTK renderers. The HTML5 canvas element provides functionality for this, but will have to be tested for speed drawbacks. It would seem that this method would bring along a multitude of advantages, such as easily creating custom text and graphic overlays, blending between different renderers and hiding the more obscure features of the XTK loading process as discussed earlier in this section, all without having to rewrite the XTK library itself. A drawback would be that a lot of UI interaction methods would have to be rewritten (such as middle-mousing over canvas changing the index, etc), but one would also have a lot more control in redesigning the user experience.

\subsubsection{Cross Browser Compatibility}

Judging from limited previous experience and source online, cross browser compatibility can be a difficult issue, as different browsers on different operating systems are implemented differently. Therefore what might work very well on Chrome could not work at all on Internet Explorer, as some functions are implemented differently or not even available in certain browsers. The use of WebGL already imposes a restriction on which browsers are usable, so it would be desirable to have at least other restrictions as possible. This is something that will have to be paid close attention to.


\section{References}
$THAT BOOK$\\
$http://www.frontiersin.org/10.3389/conf.fninf.2014.08.00101/event_abstract$\\
$http://users.loni.ucla.edu/~pipeline/paint/$\\
$http://backbonejs.org/$\\
$http://requirejs.org/$\\
$http://getbootstrap.com/$\\
$http://www.w3.org/standards/webdesign/graphics$\\

\section{Appendix}


\begin{figure}[ht!]
\centering
\includegraphics[width=170mm]{../../Design/UML_design_01.jpg}
\caption{Early UML design}
\label{fig:UIdesign1}
\end{figure}


\begin{figure}[ht]
  \begin{adjustbox}{addcode={\begin{minipage}{\width}}{\caption{%
     Early UI design
      }\end{minipage}},rotate=90,center}
      \includegraphics[scale=.45]{../../Design/UI_design_02.jpg}%
  \end{adjustbox}
\end{figure}


\end{document}
